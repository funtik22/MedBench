# RuMedTop3 — Baseline и улучшенное решение

Репозиторий содержит базовое и улучшенное решения задачи **RuMedTop3** — многоклассовой классификации медицинских кодов по текстовому описанию симптомов с метрикой **Hit@3**.

---

## Описание задачи

**Цель:**  
По тексту симптомов пациента предсказать **ТОП-3 наиболее вероятных медицинских кодов**.

**Тип задачи:**  
- Многоклассовая классификация  
- Ранжирование классов

**Основная метрика:**  
- `Hit@3` — доля примеров, в которых правильный класс попал в топ-3 предсказаний  
- Дополнительно: `Accuracy@1`

---

## Структура датасета

Каждая запись содержит:
- `idx` — уникальный идентификатор
- `symptoms` — текстовое описание симптомов (RU)
- `code` — целевой медицинский код

### Разбиение данных

| Сплит | Кол-во |
|------|-------|
| Train | 4690 |
| Dev   | 848 |
| Test  | 822 |
| Классы | 105 |

---

## Baseline решение

### Подход
- **TF-IDF** по символьным n-граммам  
  - `analyzer='char'`
  - `ngram_range=(3, 8)`
- **Logistic Regression (OvR)**  
  - L2-регуляризация  
  - `C = 10`

### Метрики (Dev)

| Метрика | Значение |
|------|---------|
| Accuracy@1 | **49.51%** |
| Hit@3 | **71.90%** |

---

## Улучшенное решение

### 1. Расширение признаков
Используется объединение двух TF-IDF представлений:

- **Char n-grams:** `(3–8)`, `max_features=50k`
- **Word n-grams:** `(1–2)`, `max_features=30k`

Итоговая размерность признакового пространства: **80 000**

---

### 2. Несколько моделей
Обучены и использованы следующие алгоритмы:

- Logistic Regression  
- LinearSVC с калибровкой вероятностей (`CalibratedClassifierCV`)  
- Multinomial Naive Bayes  
- Random Forest  

---

### 3. Rank-based ансамбль
Для объединения моделей применяется ранговое голосование:

- Каждая модель формирует упорядоченный список классов
- Баллы начисляются обратно пропорционально позиции класса в ранге
- Веса моделей пропорциональны их качеству (`Hit@3`) на Dev

---

### Метрики отдельных моделей (Dev)

| Модель | Hit@3 |
|------|------|
| Logistic Regression | 70.64% |
| LinearSVC | 68.63% |
| MultinomialNB | 65.92% |
| RandomForest | 64.27% |

---

## Итоговые метрики улучшенного решения (Dev)

| Метрика | Значение |
|------|---------|
| Accuracy@1 | **50.00%** |
| Hit@3 | **72.63%** |

---

## Сравнение решений

| Решение | Accuracy@1 | Hit@3 |
|------|------------|------|
| Baseline | 49.51% | 71.90% |
| Улучшенное (Ensemble) | **50.00%** | **72.63%** |

---

## Эксперименты с более сложными моделями

В рамках проекта также предпринимались попытки использования более сложных моделей и ансамблей, которые потенциально могут дать дополнительный прирост качества:

- `train_catboost.py` — обучение CatBoost для многоклассовой классификации  
- `train_lightgbm.py` — эксперименты с LightGBM  
- `train_rubert.py` — fine-tuning трансформерной модели RuBERT  
- папка `ensemble/` — дополнительные варианты ансамблирования моделей  

Однако обучение и подбор гиперпараметров для данных моделей требует значительно больше вычислительных ресурсов и времени.  
Из-за ограничений по времени экспериментов не удалось провести полноценный тюнинг и довести эти модели до стабильных и воспроизводимых результатов.  

Тем не менее, данный код сохранён в репозитории как задел для дальнейших улучшений.

---

## Запуск

```bash
pip install -r ../requirements.txt
python single_text_classifier.py --task-name RuMedTop3
